{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction #\n",
    "\n",
    "For a multi-dimensional SVM, the general equation is Wx+b = *value*, where W: 1xn, x: nx1, b: 1x1. It always evaluates to a scaler result.\n",
    "\n",
    "Note that for matrix multiplication, If A is an m×n matrix and B is an n×p matrix, the product AB is an m×p matrix.\n",
    "\n",
    "## Perceptron ##\n",
    "\n",
    "Basic node that is a linear boundary classifier.\n",
    "\n",
    "![PerceptronFormulaExample.PNG](PerceptronFormulaExample.PNG)\n",
    "\n",
    "![PerceptronNotations.PNG](PerceptronNotations.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Perceptrons as logical operators ###\n",
    "\n",
    "You can use perceptrons to construct the basic logical operators of AND, OR, and NOT natively. You can't do XOR though without some trickery.\n",
    "\n",
    "Important thing to realize is that for operators like AND and OR, the weights are fighting the bias. The overall goal of a perceptron is to determine if you are on the positive or negative side of a boundary, so for something like a simple AND operator with 0's and 1's as inputs, you can have any solution like:\n",
    "\n",
    "![AND%20example.png](AND%20example.png)\n",
    "\n",
    "Notice the weight symmetry. You can go from an AND to an OR operator by either increasing the weights or decreasing the bias.\n",
    "\n",
    "The NOT operator basically only has either one input or ignores all but one input. It's goal is to just return the opposite value. So something like having a weight of -1 and a bias of 0.5 works for this. Or any negative weight that's greater in magnitude than that of the positive bias.\n",
    "\n",
    "For XOR, you need to make a multi-layer NN like the following:\n",
    "\n",
    "![Perceptron_XOR_trick.PNG](Perceptron_XOR_trick.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training a Perceptron ###\n",
    "\n",
    "If you consider the case where a hyperplane is randomly dropped to divide a space, each mischaracterized point in that space can pull the plane towards it. It does this simply by adding or subtracting itself times some weighting factor known as the learning rate (generally < 1). If the point is \"above\" the plane, you subtract. If it's \"below\", you add.\n",
    "\n",
    "Example code for a tuning algorithm is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    for i in range(0, len(X)):\n",
    "        y_pred = prediction(X[i],W,b)\n",
    "        learn_rate_temp = learn_rate\n",
    "        if(y[i] == y_pred):\n",
    "            continue\n",
    "        learn_rate_temp *= y[i]-y_pred\n",
    "        W[0] += X[i][0]*learn_rate_temp\n",
    "        W[1] += X[i][1]*learn_rate_temp\n",
    "        b += learn_rate_temp\n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gradient Decent #\n",
    "\n",
    "Initial introduction and discussion is straightforward. Talked about moving in the direction that reduces error the most and warned about local minima. \n",
    "\n",
    "For a generalized error function, it needs to be both continuous and differentiable. On such function is logarithmic, since that would naturally assign very low error to correctly classified points and very high error to inproperly classified points, assuming that the shape was correct.\n",
    "\n",
    "## New type of activation function ##\n",
    "\n",
    "The first step in this process is to see what our simple step function looks like as a continuous function. A good example of that is the sigmoid function:\n",
    "\n",
    "![SigmoidActivation.PNG](SigmoidActivation.PNG)\n",
    "\n",
    "You can see the impact this has on the score of a linear segmenter like an SVM here:\n",
    "\n",
    "![SigmoidOnLinear.PNG](SigmoidOnLinear.PNG)\n",
    "\n",
    "Shown another way, we can apply this to a perceptron as the activation function, which would look like: \n",
    "\n",
    "![SigmoidPerceptron.PNG](SigmoidPerceptron.PNG)\n",
    "\n",
    "## Softmax function ##\n",
    "\n",
    "The basic sigmoid is fine and dandy for two classes. But what about many classifications? The softmax function takes care of that. It combines n exponentials to arrive at scaled probabilities for n classes. Fun fact - if n == 2, this function equates to the sigmoid function if your scores/classifications are -1 and 0.\n",
    "\n",
    "![Softmax.PNG](Softmax.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Write a function that takes as input a list of numbers, and returns\n",
    "# the list of values given by the softmax function.\n",
    "def softmax(L):\n",
    "    denom = 0.\n",
    "    for x in range(0, len(L)):\n",
    "        denom += math.exp(L[x])\n",
    "        \n",
    "    valueList = []\n",
    "    for x in range(0, len(L)):\n",
    "        valueList.insert(len(valueList), math.exp(L[x]) / denom)\n",
    "    \n",
    "    return valueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(L):\n",
    "    expL = np.exp(L)\n",
    "    sumExpL = sum(expL)\n",
    "    result = []\n",
    "    for i in expL:\n",
    "        result.append(i*1.0/sumExpL)\n",
    "    return result\n",
    "    \n",
    "    # Note: The function np.divide can also be used here, as follows:\n",
    "    # def softmax(L):\n",
    "    #     expL(np.exp(L))\n",
    "    #     return np.divide (expL, expL.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-Hot Encoding - How to numerically encode unrelated things #\n",
    "\n",
    "When making a system that tries to classify unrelated things, you don't want to have sequential enumerations between them for the learning system. Even though this works fine for humans, the machine doesn't think that way. In order to enforce separation between the items, we make row vectors that have n columns. This looks like the following:\n",
    "\n",
    "![One-Hot.PNG](One-Hot.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cross Entropy and Maximum Likelihood #\n",
    "\n",
    "Viewing things as probabilities brings up some issues. The first is that it inherently makes things a maximization problem. Generally speaking optimizers work by minimizing i.e. driving an error function to zero (such as gradient descent). The second is that calculating the conditional probability of something is a multiplicative problem that can produce very small numbers. This makes the solution ultimately very sensitive to changes in any one value, more computationally expensive, and subject to floating point issues on a computer.\n",
    "\n",
    "The solution to this is to work in a logarithmic space. Logarithms allow us to turn a multiplication problem into an addition problem, since log(abc) = log(a) + log(b) + log(c). Also, the scale of the numbers is far more manageable, and the range is exactly what we want for an error function operating on values that have a range between 0 and 1. If we have a probability of 1 - certain and very unlikely - we have an error of 0. Likewise, if we have a probability of 0 - basically impossible and being absolutely wrong - we have an error of -infinity.\n",
    "\n",
    "Now, we don't want to work in negative space, so we simply take the negative of the log of the probability. Also, by convention (and since we're working with exponentials), we take the sum of the negative natural logs of the probabilities.\n",
    "\n",
    "This sum, taken across a data set with a certain classification function, is known as the cross entropy.\n",
    "\n",
    "![crossEntropy.PNG](crossEntropy.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "def cross_entropy(Y, P):\n",
    "    logL = np.log(P) # exponent list if all probabilities\n",
    "    yL = np.array(Y)\n",
    "    crossEntropy = -np.sum(yL * logL + (1-yL)*np.log(1 - np.array(P)))\n",
    "    return crossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667497\n"
     ]
    }
   ],
   "source": [
    "# Combining some formulas, we have a simplified versison here\n",
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# ToDo: Print cross entropy from session\n",
    "cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={softmax: softmax_data, one_hot: one_hot_data}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For instances where we have multiple classes, the formula for cross entropy then becomes:\n",
    "\n",
    "![multi-class_cross.PNG](multi-class_cross.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression #\n",
    "\n",
    "All of these tools combine to form the general optimization framework for learning systems known as Logistic Regression. The basic 50,000 foot outline is:\n",
    "\n",
    "* Take your data\n",
    "* Pick a random model\n",
    "* Calculate the error\n",
    "* Minimize the error, and obtain a better model\n",
    "* Enjoy!\n",
    "\n",
    "Sounds great, but we need a few tools. The first is the error function that we want to minimize. That's formed as follows:\n",
    "\n",
    "![ErrorFunction.PNG](ErrorFunction.PNG)\n",
    "\n",
    "This generalizes with the multiclass formula as follows:\n",
    "\n",
    "![GeneralErrorFunction.PNG](GeneralErrorFunction.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gradient Descent #\n",
    "\n",
    "Gradient descent, in general, involves taking the gradient of the describing error function and moving in the direction that causes the error to decrease the most. For a simple error function like a linear classifier mapped onto a sigmoid function as we've been dealing with here, it's very straight forward.\n",
    "\n",
    "![PartialEw.gif](PartialEw.gif)\n",
    "\n",
    "![PartialEb.gif](PartialEb.gif)\n",
    "\n",
    "![GradE.PNG](GradE.PNG)\n",
    "\n",
    "\"The gradient is actually a scalar times the coordinates of the point! And what is the scalar? Nothing less than a multiple of the difference between the label and the prediction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implement the following functions\n",
    "\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.matmul(features,weights)+bias)\n",
    "\n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return -y * np.log(output) - (1 - y) * np.log(1 - output)\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    error = -(y - output_formula(x, weights, bias))\n",
    "    weights -= learnrate * error * x\n",
    "    bias -= learnrate * error\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Interesting difference between the Perceptron algorithm and gradient descent is that GD listens to all points, with correctly classified ones pushing the boundaries away and incorrect ones pulling them in. Perceptron only listens to incorrectly classified points. Also, GD is a continuous method, following the \"magnetic\" field of the sigmoid function instead of the discrete behavior of the Perceptron algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ca3da2e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ca4e0a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ca51beda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Some helper functions for plotting and drawing lines\n",
    "\n",
    "def plot_points(X, y):\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'red', edgecolor = 'k')\n",
    "\n",
    "def display(m, b, color='g--'):\n",
    "    plt.xlim(-0.05,1.05)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    x = np.arange(-10, 10, 0.1)\n",
    "    plt.plot(x, m*x+b, color)\n",
    "\n",
    "data = pd.read_csv('../deep-learning/gradient-descent/data.csv', header=None)\n",
    "X = np.array(data[[0,1]])\n",
    "y = np.array(data[2])\n",
    "plot_points(X,y)\n",
    "plt.show()\n",
    "\n",
    "# Implement the following functions\n",
    "\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    return sigmoid(np.matmul(features,weights)+bias)\n",
    "\n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    return -y * np.log(output) - (1 - y) * np.log(1 - output)\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    error = -(y - output_formula(x, weights, bias))\n",
    "    weights -= learnrate * error * x\n",
    "    bias -= learnrate * error\n",
    "    return weights, bias\n",
    "\n",
    "np.random.seed(44)\n",
    "\n",
    "epochs = 100\n",
    "learnrate = 0.01\n",
    "\n",
    "def train(features, targets, epochs, learnrate, graph_lines=False):\n",
    "    \n",
    "    errors = []\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "    bias = 0\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features, targets):\n",
    "            output = output_formula(x, weights, bias)\n",
    "            error = error_formula(y, output)\n",
    "            weights, bias = update_weights(x, y, weights, bias, learnrate)\n",
    "        \n",
    "        # Printing out the log-loss error on the training set\n",
    "        out = output_formula(features, weights, bias)\n",
    "        loss = np.mean(error_formula(targets, out))\n",
    "        errors.append(loss)\n",
    "        #if e % (epochs / 10) == 0:\n",
    "        #    print(\"\\n========== Epoch\", e,\"==========\")\n",
    "        #    if last_loss and last_loss < loss:\n",
    "        #        print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        #    else:\n",
    "        #        print(\"Train loss: \", loss)\n",
    "        #    last_loss = loss\n",
    "        #    predictions = out > 0.5\n",
    "        #    accuracy = np.mean(predictions == targets)\n",
    "        #    print(\"Accuracy: \", accuracy)\n",
    "        if graph_lines and e % (epochs / 100) == 0:\n",
    "            display(-weights[0]/weights[1], -bias/weights[1])\n",
    "            \n",
    "\n",
    "    # Plotting the solution boundary\n",
    "    plt.title(\"Solution boundary\")\n",
    "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
    "\n",
    "    # Plotting the data\n",
    "    plot_points(features, targets)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the error\n",
    "    plt.title(\"Error Plot\")\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Error')\n",
    "    plt.plot(errors)\n",
    "    plt.show()\n",
    "\n",
    "train(X, y, epochs, learnrate, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Important note about GD ##\n",
    "\n",
    "Since GD as we've been looking at it here uses the sigmoid function as its activation function, it's important to note that we want all of our input values to be zero mean, with a fairly tight standard deviation (around 1 or so), since anything too far away from zero gets either squashed to zero or slammed to one.\n",
    "\n",
    "Another thing to look out for is that as the data sets get large, you need to scale the update step i.e. learning rate by the number of data points that you have overall. This scaling of the error changes the naive SSE function to a Mean of Squared Error (MSE), which keeps the learning rate at a reasonable range (0.01 to 0.001) while also making sure that the algorithm itself stays stable and doesn't diverge in really weird ways. To see the difference between a straight-up implementation vs. one with scaling, compare the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \"\"\"\n",
    "    # Derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "learnrate = 0.5\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)\n",
    "\n",
    "# Initial weights\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "\n",
    "### Calculate one gradient descent step for each weight\n",
    "### Note: Some steps have been consilated, so there are\n",
    "###       fewer variable names than in the above sample code\n",
    "\n",
    "# TODO: Calculate the node's linear combination of inputs and weights\n",
    "h = np.matmul(x,w)\n",
    "\n",
    "# TODO: Calculate output of neural network\n",
    "nn_output = sigmoid(h)\n",
    "\n",
    "# TODO: Calculate error of neural network\n",
    "error = y - nn_output\n",
    "\n",
    "# TODO: Calculate the error term\n",
    "#       Remember, this requires the output gradient, which we haven't\n",
    "#       specifically added a variable for.\n",
    "error_term = error * sigmoid_prime(h)\n",
    "\n",
    "# TODO: Calculate change in weights\n",
    "del_w = learnrate * error_term * x\n",
    "\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# TODO: We haven't provided the sigmoid_prime function like we did in\n",
    "#       the previous lesson to encourage you to come up with a more\n",
    "#       efficient solution. If you need a hint, check out the comments\n",
    "#       in solution.py from the previous lecture.\n",
    "def sigmoid_prime_x(sig):\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Note: We haven't included the h variable from the previous\n",
    "        #       lesson. You can add it if you want, or you can calculate\n",
    "        #       the h together with the output\n",
    "\n",
    "        # TODO: Calculate the output\n",
    "        output = sigmoid(np.matmul(x,weights))\n",
    "\n",
    "        # TODO: Calculate the error\n",
    "        error = y - output\n",
    "\n",
    "        # TODO: Calculate the error term\n",
    "        error_term = error * sigmoid_prime_x(output)\n",
    "\n",
    "        # TODO: Calculate the change in weights for this sample\n",
    "        #       and add it to the total weight change\n",
    "        del_w += error_term * x\n",
    "\n",
    "    # TODO: Update weights using the learning rate and the average change in weights\n",
    "    weights += del_w * (learnrate / len(features.values))\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Gradient Descent for Regression Fitting ##\n",
    "\n",
    "Gradient descent can be readily adapted to the problem of linear regression instead of classification. The main change between the two is in the error function used. In the bi-modal classification example, the error was simply a function of how far away the point was from the correct side of the dividing line, scaled by the sigmoid function to be between 0 and 1.\n",
    "\n",
    "For a regression, the goal is still to \"float\" the line to the center of the data. However the error function will seek to minimize the overall distance that all of the points are from the line. The two main error functions that we'll use for this are Sum of Absolute Difference and Sum of Square Difference (SAD and SSD). Each is scaled to the number of data points in the total set to keep the numbers in a similar range regardless of size of data set (technically, 1/m for SAD, 1/2m for SSD).\n",
    "\n",
    "Updates are accomplished the same way as they are above, since that's the crux of gradient descent (i.e. how the error function is used to update the weights of the linear equation).\n",
    "\n",
    "![MeanSquareError.PNG](MeanSquareError.PNG)\n",
    "\n",
    "![AbsoluteError.PNG](AbsoluteError.PNG)\n",
    "\n",
    "There are two ways to apply this analysis - calculate the cummulative error and then do one single update step (batch) or update the weights after each individual point evaluation (stochastic).\n",
    "\n",
    "![BatchVsStochastic.PNG](BatchVsStochastic.PNG)\n",
    "\n",
    "In practice, the best way to analyze large sets of points is to use the *mini-batch* method, which divides the points into small batches and treats each as a sort of stochastic step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Networks #\n",
    "\n",
    "Neural nets take the individual constructs from above, those simple classifiers, and combine them together again using the basic perceptron or sigmoid functions. This allows for complex regions to be formed that, while individually may be linear, are actually non-linear in shape. When you start constructing these multi-layer configurations, you end up with a number of \"hidden layers\" in between the inputs and the output. The general structure looks like:\n",
    "\n",
    "![nn_hidden_layer.PNG](nn_hidden_layer.PNG)\n",
    "\n",
    "\"Each row in the matrix will correspond to the weights leading out of a single input unit, and each column will correspond to the weights leading in to a single hidden unit.\"\n",
    "\n",
    "![input-times-weights.png](input-times-weights.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Back Propogation #\n",
    "\n",
    "Going forward is all well and good, but ultimately we need to be able to train the network. In order to do that, we'll need to to update the weights throughout the network. That requires a techniques known as back propagation. Regarding the notation below, error refers to the strict error - the difference between expected and calculated. Error term, however, is a shorthand notation (denoted as sigma in some of their math) for Error * f'(h), where f'(h) is the derivative of the activation function. Here the activation function is shown as being a function of the layer output (h for hidden layer output in this example). Refer to the following code segment to see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate output error\n",
    "error = target - output # output error\n",
    "\n",
    "# TODO: Calculate error term for output layer\n",
    "output_error_term = error * output * (1 - output) # output error times the gradient\n",
    "\n",
    "# TODO: Calculate error term for hidden layer\n",
    "hidden_error_term = np.dot(output_error_term, weights_hidden_output) * \\ # Error from the hidden layer\n",
    "                    hidden_layer_output * (1 - hidden_layer_output) # Hidden layer gradient\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = learnrate * output_error_term * hidden_layer_output # Here the outputs of the hidden layer are the inputs\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_h = learnrate * hidden_error_term * x[:, None] # Same as the simple gradient decent example\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that just like in forward propagation, we start by calculating the error between the target and the output, which is then multiplied by the gradient of the output to get the output_error_term. We then back propagate this error term by multiplying by the weight of the branch to get the hidden layer error, and multiplying that by the hidden layers gradient. Now we can update all of the weights. First, the hidden layers weight is then update by multiplying the output error term by the output of the hidden layer itself. Then ther input layer weights are update by multiplying the inputs by the error term from the hidden layer. Both are scaled by the learning rate.\n",
    "\n",
    "The main takeaway here is that the weight of any given layer is updated by taking the error of the previous layer, multiplying it by the gradient of that layer, then multiplying that by inputs to that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
