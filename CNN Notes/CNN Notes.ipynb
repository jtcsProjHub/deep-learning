{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Neural Networks #\n",
    "\n",
    "As we start to attack larger, more complicated data sets, the networks themselves also become much larger. If we stick with what we learned about simple neural networks and expand upon it, we get what's called Multi-Layer Perceptrons, or MLP's. As an example, we'll examine hand writing analysis for clean, grayscale images with distinct black backgrounds. All samples are the same size and of the numbers 0-9. Visually, the network would look something like the following:\n",
    "\n",
    "<img src=\"FullMLP.PNG\" style=\"height: 500px;\"/>\n",
    "\n",
    "Note that we have to flatten the image array to a linear input vector. As before all of the input nodes are fully connected to the nodes in the hidden layer. Here we see the direct limitations of MLP's. A consequence of all of the layers being fully connected causes both a large increase in computational requirements and a loss of locational context between data and node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706.0\n",
      "Trainable params: 669,706.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,784)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the prime innovations moving us from MLP's to CNN's is the concept of Regional Networks. Such arrangements only connect certain nodes to certain weights. Looking at a 2D array of data for something like an image, we end up with:\n",
    "\n",
    "<img src=\"RegionalNetwork.PNG\" style=\"height: 500px;\"/>\n",
    "\n",
    "From here, the configuration can be further simplified by using weight matrices instead of vectors:\n",
    "\n",
    "<img src=\"RegionalNetworkMatrix.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN Structure #\n",
    "\n",
    "Another major change in CNN's is how they take in and operate on input data. The input here is a matrix that is sized proportional to a region of data that you think needs to analyzed to detect a feature of relevant size, relative to the overall data. Note that you don't have to know *what* the feature will be, only an appropriate filter size. Comparing this to image processing, think of typical image kernals like edge detectors. Additionally, you can specify **how many** filters are used, and how those filters march along the data. The results of these filters are then \"convolved\" together in a new layer, known as a *convolutional layer*.\n",
    "\n",
    "<img src=\"CNN_Input_handling.PNG\" style=\"height: 500px;\"/>\n",
    "\n",
    "For a CNN with multiple filters, they could end up with iterating to something like this:\n",
    "\n",
    "<img src=\"MultipleFilters.PNG\" style=\"height: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For a color vs. grayscale image, the only difference would be a multi-dimensional input, with the filter set operating on each \"layer\" of the input array. Note that during the fitting process, the network will create filters that work at finding features across all of the different layers. The convolutional layer holds the results of the different filters for analysis.\n",
    "\n",
    "<img src=\"CNN_MultiInputLayerMultiFilter.PNG\" style=\"height: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 63, 63, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896.0\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='valid', \n",
    "    activation='relu', input_shape=(128, 128, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pooling Layers #\n",
    "\n",
    "The last unique layer to a CNN is called the *pooling layer*. It's responsibility is to reduce the results from a convolutional layer down to a more manageable amount of dimensions. The goal for structuring these layers is to decimate the data enough so that the next layer is more efficient, but not so much that it looses meaningful data. Some typical pooling layer reduction methods include max pooling (max value contained within filter window), global average pooling (average of all values in filter layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 15)        0         \n",
      "=================================================================\n",
      "Total params: 0.0\n",
      "Trainable params: 0.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=2, strides=2, input_shape=(100, 100, 15)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it together #\n",
    "\n",
    "The overall goal of alternating convolutional and pooling layers is to go from spacially related data to an overall signature vector for what the image contains. The signature vector is then used as an input vector to an MLP, which outputs a set of probabilities as to what category item may be contained within the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 528,054.0\n",
      "Trainable params: 528,054.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how, despite there still being a large number of parameters here overall, the total number of trainable parameters is still smaller than the comparatively shallow MLP shown above in the beginning of the notes (670k MLP vs. 530k CNN). On top of that, you have a network that can more accurately describe the spatial data contained in the input set, since the network is connected in a way that preserves that information. This makes the CNN both more easy to train and more robust to less \"clean\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
